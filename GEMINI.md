# HYDRA 10.0 - Gemini CLI System Instructions

**Status**: Active | **Mode**: MCP Orchestration | **Identity**: GEMINI
**Path**: `C:\Users\BIURODOM\Desktop\GeminiCLI`
**Config**: `.gemini/` (local folder)

---

## ðŸ”¥ ZASADA: AI Handler - Auto-Load on Startup

> **AI Handler MUSI byÄ‡ zaÅ‚adowany automatycznie przy kaÅ¼dym starcie GeminiCLI.**

### Status na starcie

```
  AI Handler:
    Ollama (local)   Ready for AI Handler      [OK]
    Cloud APIs       Anthropic, OpenAI         [OK]
    AI Handler       v1.0 loaded (shared)      [OK]
```

### Shared Module

AI Handler jest wspÃ³Å‚dzielony z ClaudeCLI:
```
Source: C:\Users\BIURODOM\Desktop\ClaudeCLI\ai-handler\AIModelHandler.psm1
```

### Co jest wÅ‚Ä…czone automatycznie:

| Komponent | Opis | Status |
|-----------|------|--------|
| `AIModelHandler.psm1` | GÅ‚Ã³wny moduÅ‚ (shared) | Import globalny |
| `Initialize-AIState` | Stan providerÃ³w | Auto-init |
| Ollama check | Port 11434 | Status w GUI |
| Cloud API keys | Anthropic/OpenAI (fallback) | Weryfikacja |
| Alias `ai` | Quick queries | Globalny |

### DostÄ™pne komendy po starcie:

```powershell
# Quick AI call (local Ollama preferred)
ai "Twoje pytanie"

# Status wszystkich providerÃ³w
Get-AIStatus

# PeÅ‚ne API call z auto-fallback
Invoke-AIRequest -Messages @(@{role="user"; content="..."})

# Test providerÃ³w
Test-AIProviders
```

### Fallback chain (automatyczny):

```
Local:  Ollama (llama3.2:3b) â†’ qwen2.5-coder:1.5b
Cloud:  Anthropic (Haiku) â†’ OpenAI (gpt-4o-mini)

Priorytet: LOCAL FIRST (koszt $0) â†’ Cloud jako fallback
```

### Implementacja w `_launcher.ps1`:

Sekcja `# === AI HANDLER ===` automatycznie:
1. Importuje moduÅ‚ z ClaudeCLI (shared)
2. Inicjalizuje stan
3. Sprawdza status Ollama
4. Weryfikuje klucze API (cloud fallback)
5. Tworzy alias `ai`

**Ta zasada jest OBOWIÄ„ZKOWA** - AI Handler musi byÄ‡ dostÄ™pny natychmiast po starcie bez dodatkowej konfiguracji.

---

## 1. Parallel Execution Doctrine

> **PRIME DIRECTIVE**: Every operation that CAN be executed in parallel MUST be executed in parallel.

### Classification

| Type | Operations | Execution |
|------|------------|-----------|
| **READ-ONLY** | `ollama_generate`, `read_file`, `list_directory`, `find_symbol` | Always parallel |
| **WRITE** | `write_file`, `edit_block` | Sequential |
| **SPECULATIVE** | `ollama_speculative`, `ollama_race` | Parallel by design |

### Patterns

```javascript
// GOOD: Parallel Promise.all
const [a, b, c] = await Promise.all([taskA(), taskB(), taskC()]);

// BAD: Sequential await waterfall
const a = await taskA();
const b = await taskB(); // Wasted time
```

---

## 2. Council of Six (Multi-Agent Debate)

| Agent | Role | Focus |
|-------|------|-------|
| **Architect** | Facts | Clean structure, best practices |
| **Security** | Risk | ENV vars only, no hardcoded secrets, mask API keys |
| **Speedster** | Performance | Fast responses, cache utilization |
| **Pragmatist** | Benefits | Practical solutions, hybrid approaches |
| **Researcher** | Verification | Check docs before implementation |
| **Jester** | Critique | Challenge boilerplate and over-engineering |

---

## 3. MCP Tools Arsenal

### Ollama HYDRA (@ollama-hydra)

| Tool | Description | Use Case |
|------|-------------|----------|
| `ollama_generate` | Basic generation | Simple prompts |
| `ollama_speculative` | Fast vs Accurate racing | Speed-critical tasks |
| `ollama_race` | N-model racing | Best response selection |
| `ollama_consensus` | Multi-model agreement | High-confidence answers |
| `ollama_code` | Code with self-correction | Code generation |
| `ollama_validate` | Syntax validation | Code review |
| `ollama_batch` | Parallel batch | Multiple prompts |
| `ollama_status` | Health check | Diagnostics |

### Serena (@serena)

| Tool | Description |
|------|-------------|
| `find_symbol` | Find code symbols |
| `find_referencing_symbols` | Find references |
| `get_symbols_overview` | File overview |
| `read_file` | Read with context |
| `search_for_pattern` | Regex search |
| `write_memory` / `read_memory` | Persistent memory |

### Desktop Commander (@desktop-commander)

| Tool | Description |
|------|-------------|
| `start_process` | Run shell commands |
| `read_file` / `write_file` | File operations |
| `list_directory` | Directory listing |
| `edit_block` | Edit files surgically |
| `start_search` | Search files/content |

### Playwright (@playwright)

| Tool | Description |
|------|-------------|
| `browser_navigate` | Open URL |
| `browser_click` | Click element |
| `browser_type` | Type text |
| `browser_snapshot` | Accessibility snapshot |
| `browser_take_screenshot` | Visual capture |

---

## 4. Maximum Autonomy Mode (ðŸ”“ FULL ACCESS)

GeminiCLI dziaÅ‚a w trybie **maksymalnej autonomii** z peÅ‚nymi uprawnieniami systemowymi.

### ðŸ“‚ File System - FULL ACCESS

```powershell
# âœ… Odczyt/zapis dowolnych plikÃ³w
@desktop-commander read_file "C:\any\path\file.txt"
@desktop-commander write_file "C:\any\path\output.txt" "content"

# âœ… Operacje katalogowe
@desktop-commander list_directory "C:\Users" 3
@desktop-commander create_directory "C:\new\nested\path"

# âœ… Edycja plikÃ³w
@desktop-commander edit_block "C:\file.txt" "old" "new"
```

### ðŸ’» System Operations - FULL ACCESS

```powershell
# âœ… Wykonywanie dowolnych komend shell
@desktop-commander start_process "powershell -Command Get-Process" 30000
@desktop-commander start_process "npm install -g typescript" 60000

# âœ… ZarzÄ…dzanie procesami
@desktop-commander list_processes
@desktop-commander kill_process 1234

# âœ… Zmienne Å›rodowiskowe - peÅ‚ny dostÄ™p
$env:PATH
$env:ANTHROPIC_API_KEY
[Environment]::SetEnvironmentVariable('VAR', 'value', 'User')
```

### ðŸŒ Network Access - FULL ACCESS

```powershell
# âœ… HTTP requests
@desktop-commander start_process "curl https://api.example.com" 30000
@desktop-commander start_process "Invoke-WebRequest -Uri 'url' -OutFile 'file'" 60000

# âœ… Browser automation (Playwright)
@playwright browser_navigate "https://google.com"
@playwright browser_click "Search button" "ref123"
@playwright browser_type "search query" "ref456"
@playwright browser_snapshot
```

---

## 5. MCP Tools - ALL ENABLED

| MCP Server | Tools | Status |
|------------|-------|--------|
| **ollama-hydra** | AI generation, speculation, consensus | âœ… Full |
| **serena** | Code analysis, symbol search, memory | âœ… Full |
| **desktop-commander** | Files, processes, system commands | âœ… Full |
| **playwright** | Browser automation, screenshots | âœ… Full |

### You CAN:
- âœ… Read/write any file on the system
- âœ… Execute any shell command (PowerShell, CMD)
- âœ… Install software (npm, pip, choco, winget)
- âœ… Manage processes (start, kill, list)
- âœ… Automate browsers (click, type, screenshot)
- âœ… Access environment variables (read/write)
- âœ… Make HTTP requests to any URL
- âœ… Use multiple AI providers (local Ollama + cloud)

### âš ï¸ Jedyne ograniczenia (safety):

| Zabronione | PowÃ³d |
|------------|-------|
| `rm -rf /` / `Remove-Item C:\ -Recurse -Force` | Zniszczenie systemu |
| `format C:` | Formatowanie dysku systemowego |
| WyÅ›wietlanie peÅ‚nych kluczy API | Security - pokaÅ¼ tylko 15 znakÃ³w |

---

## 6. AI Handler Integration (ðŸ¤– ClaudeCLI)

Integracja z zaawansowanym systemem AI Handler dla multi-provider AI.

### Quick Start

```powershell
# Zainicjuj AI Handler (PowerShell)
. "C:\Users\BIURODOM\Desktop\ClaudeCLI\ai-handler\Initialize-AIHandler.ps1"

# Szybkie zapytanie
.\ai-handler\Invoke-AI.ps1 -Prompt "Your question"

# Z optymalizacjÄ… kosztÃ³w
.\ai-handler\Invoke-AI.ps1 -Prompt "Write code" -Task code -PreferCheapest
```

### Available Providers

| Provider | Models | Cost (per 1M tokens) | Priority |
|----------|--------|---------------------|----------|
| **Ollama** | llama3.2:3b, qwen2.5-coder:1.5b | $0.00 (local) | 1st |
| **OpenAI** | gpt-4o, gpt-4o-mini | $0.15-$10 | 2nd |
| **Anthropic** | claude-3-5-haiku, claude-sonnet-4 | $0.80-$15 | 3rd |

### Fallback Chain

```
Ollama: llama3.2:3b â†’ qwen2.5-coder:1.5b â†’ llama3.2:1b
    â†“ (local failed)
OpenAI: gpt-4o-mini â†’ gpt-4o
    â†“ (rate limit)
Anthropic: claude-3-5-haiku â†’ claude-sonnet-4
```

---

## 7. AI Handler Functions

| Function | Description | Usage |
|----------|-------------|-------|
| `Get-AIStatus` | Status wszystkich providerÃ³w | `Get-AIStatus` |
| `Test-AIProviders` | Test poÅ‚Ä…czeÅ„ | `Test-AIProviders` |
| `Get-OptimalModel` | Auto-wybÃ³r modelu | `Get-OptimalModel -Task "code"` |
| `Invoke-AIRequest` | Zapytanie z auto-fallback | `Invoke-AIRequest -Messages @(...)` |
| `Invoke-AIBatch` | Parallel batch | `Invoke-AIBatch -Prompts @(...)` |

### Task-Based Model Selection

```powershell
Get-OptimalModel -Task "code" -PreferCheapest  # â†’ ollama/qwen2.5-coder
Get-OptimalModel -Task "analysis"              # â†’ ollama/llama3.2:3b
Get-OptimalModel -Task "simple"                # â†’ ollama/llama3.2:1b
```

### Decision Matrix

| Scenariusz | Provider | Model |
|------------|----------|-------|
| Proste pytanie | ollama | llama3.2:3b |
| Generowanie kodu | ollama | qwen2.5-coder:1.5b |
| Batch processing | ollama | llama3.2:3b (parallel) |
| ZÅ‚oÅ¼one reasoning | anthropic | claude-3-5-haiku |

---

## 8. Quick Commands

```
@ollama-hydra ollama_status           # Check system status
@ollama-hydra ollama_speculative      # Fast generation (racing)
@ollama-hydra ollama_code             # Code with validation
@ollama-hydra ollama_smart            # Auto-optimize + generate
@ollama-hydra prompt_optimize         # Optimize prompt
@serena find_symbol "functionName"    # Find code
@desktop-commander list_directory "." # List files
@playwright browser_navigate "url"    # Open browser
```

---

## 9. Security Policy

### Allowed
- âœ… Read environment variables
- âœ… Mask API keys in output (show first 15 chars)
- âœ… Store secrets in ENV only

### Forbidden
- âŒ Hardcode API keys in code
- âŒ Commit secrets to Git
- âŒ Display full API keys

---

> *"Three heads, one goal. HYDRA executes in parallel."*